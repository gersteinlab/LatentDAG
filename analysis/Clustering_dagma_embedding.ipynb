{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "062284c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import pymde\n",
    "import hdbscan\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76670170",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/slayman/pi/gerstein/jg2447/conda_envs/DAG/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/gpfs/slayman/pi/gerstein/jg2447/conda_envs/DAG/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "p_nw = []\n",
    "p_net_nw = []\n",
    "loss_nw = []\n",
    "loss_net_nw = []\n",
    "bool_nw = []\n",
    "\n",
    "for network_name in [\"DAGMA_thresholdAdaptive\"]:\n",
    "    \n",
    "    # measurements across 10 random sample split\n",
    "    p_rs = []\n",
    "    p_net_rs = []\n",
    "    loss_rs = []\n",
    "    loss_net_rs = []\n",
    "    bool_rs = []\n",
    "    \n",
    "    for rs in range(10):\n",
    "        # read data\n",
    "        X_train = pd.read_csv(\"../../result/input_perturb_phyloP/%d/X_train_stratified\" % rs, sep=\"\\t\", index_col=0).values\n",
    "        X_valid = pd.read_csv(\"../../result/input_perturb_phyloP/%d/X_valid_stratified\" % rs, sep=\"\\t\", index_col=0).values\n",
    "        X_test = pd.read_csv(\"../../result/input_perturb_phyloP/%d/X_test_stratified\" % rs, sep=\"\\t\", index_col=0).values\n",
    "        Y_test = pd.read_csv(\"../../result/input_perturb_phyloP/%d/Y_test_stratified\" % rs, sep=\"\\t\", index_col=0).values.reshape(-1)\n",
    "        Y_test_gene = pd.read_csv(\"../../result/input_perturb_phyloP/%d/Y_test_stratified\" % rs, sep=\"\\t\", index_col=0).index\n",
    "\n",
    "        test_mask = np.concatenate([[False] * len(X_train), [False] * len(X_valid), [True] * len(X_test)])\n",
    "\n",
    "        # mask of whether a test node is in the DAGMA graph\n",
    "        dag = pd.read_csv(\"../../result/network_perturb_phyloP/DAGMA_thresholdAdaptive.tsv\", sep=\"\\t\", header=None)\n",
    "        id2genes = pd.read_csv(\"../../result/network_perturb_phyloP/valid_genes\", sep=\"\\t\").set_index(\"ID\")['genes'].to_dict()\n",
    "        dag[0] = dag[0].map(id2genes)\n",
    "        dag[1] = dag[1].map(id2genes)\n",
    "        dag_genes = list(set.union(set(dag[0]), set(dag[1])))\n",
    "        test_inDAG = Y_test_gene.isin(dag_genes)\n",
    "\n",
    "        # measurements across 10 random init repeats\n",
    "        p_rep = []\n",
    "        p_net_rep = []\n",
    "        loss_rep = []\n",
    "        loss_net_rep = []\n",
    "\n",
    "        for rep in range(10):\n",
    "            prefix = \"../../result/model_perturb_phyloP/%s/%d/model%d\" % (network_name, rs, rep)\n",
    "            with open(prefix+\".para\", \"rb\") as f:\n",
    "                best_params, X1, out, loss1, loss2 = pickle.load(f)\n",
    "            Y_pred = out[test_mask].reshape(-1)\n",
    "\n",
    "            loss_rep.append(F.mse_loss(torch.tensor(Y_test), torch.tensor(Y_pred)).item())\n",
    "            loss_net_rep.append(F.mse_loss(torch.tensor(Y_test[test_inDAG]), torch.tensor(Y_pred[test_inDAG])).item())\n",
    "            p_rep.append(pearsonr(Y_test, Y_pred)[0])\n",
    "            p_net_rep.append(pearsonr(Y_test[test_inDAG], Y_pred[test_inDAG])[0])\n",
    "        bool_rep = ~np.isnan(np.array(p_net_rep))\n",
    "\n",
    "        p_rs.append(p_rep)\n",
    "        p_net_rs.append(p_net_rep)\n",
    "        loss_rs.append(loss_rep)\n",
    "        loss_net_rs.append(loss_net_rep)\n",
    "        bool_rs.append(bool_rep)\n",
    "        \n",
    "    p_nw.append(p_rs)\n",
    "    p_net_nw.append(p_net_rs)\n",
    "    loss_nw.append(loss_rs)\n",
    "    loss_net_nw.append(loss_net_rs)\n",
    "    bool_nw.append(bool_rs)\n",
    "\n",
    "p_nw = np.array(p_nw)\n",
    "p_net_nw = np.array(p_net_nw)\n",
    "loss_nw = np.array(loss_nw)\n",
    "loss_net_nw = np.array(loss_net_nw)\n",
    "bool_nw = np.array(bool_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "420be4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanargmin(loss_nw[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40726ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = \"DAGMA_thresholdAdaptive\"\n",
    "rs = 8\n",
    "rep = 9\n",
    "\n",
    "# read data\n",
    "X_train = pd.read_csv(\"../../result/input_perturb_phyloP/%d/X_train_stratified\" % rs, sep=\"\\t\", index_col=0).values\n",
    "X_valid = pd.read_csv(\"../../result/input_perturb_phyloP/%d/X_valid_stratified\" % rs, sep=\"\\t\", index_col=0).values\n",
    "X_test = pd.read_csv(\"../../result/input_perturb_phyloP/%d/X_test_stratified\" % rs, sep=\"\\t\", index_col=0).values\n",
    "Y_test = pd.read_csv(\"../../result/input_perturb_phyloP/%d/Y_test_stratified\" % rs, sep=\"\\t\", index_col=0).values.reshape(-1)\n",
    "Y_test_gene = pd.read_csv(\"../../result/input_perturb_phyloP/%d/Y_test_stratified\" % rs, sep=\"\\t\", index_col=0).index\n",
    "\n",
    "test_mask = np.concatenate([[False] * len(X_train), [False] * len(X_valid), [True] * len(X_test)])\n",
    "\n",
    "# mask of whether a test node is in the DAGMA graph\n",
    "dag = pd.read_csv(\"../../result/network_perturb_phyloP/DAGMA_thresholdAdaptive.tsv\", sep=\"\\t\", header=None)\n",
    "id2genes = pd.read_csv(\"../../result/network_perturb_phyloP/valid_genes\", sep=\"\\t\").set_index(\"ID\")['genes'].to_dict()\n",
    "dag[0] = dag[0].map(id2genes)\n",
    "dag[1] = dag[1].map(id2genes)\n",
    "dag_genes = list(set.union(set(dag[0]), set(dag[1])))\n",
    "test_inDAG = Y_test_gene.isin(dag_genes)\n",
    "\n",
    "prefix = \"../../result/model_perturb_phyloP/%s/%d/model%d\" % (network_name, rs, rep)\n",
    "with open(prefix+\".para\", \"rb\") as f:\n",
    "    best_params, X1, out, loss1, loss2 = pickle.load(f)\n",
    "Y_pred = out[test_mask].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53c32c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-norm expression profile from given data\n",
    "X = X1\n",
    "X_norm = StandardScaler().fit_transform(X)\n",
    "\n",
    "# # init with spectral embed\n",
    "# se = SpectralEmbedding(n_components=20, affinity='nearest_neighbors', n_neighbors=7, eigen_solver='arpack')\n",
    "# X_norm_se = se.fit_transform(X_norm)\n",
    "\n",
    "# mde embed\n",
    "mde = pymde.preserve_neighbors(X_norm, embedding_dim=20, n_neighbors=7, repulsive_fraction=5)\n",
    "X_norm_se_mde = mde.embed()\n",
    "pd.DataFrame(X_norm_se_mde).to_csv(\"../../result/emb/mde_dagma.txt\", sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "# clustering\n",
    "clusterer = hdbscan.HDBSCAN(metric='euclidean', min_cluster_size=10, min_samples=10, cluster_selection_method='leaf')\n",
    "cluster_label_X = clusterer.fit_predict(X_norm_se_mde)\n",
    "pd.DataFrame(cluster_label_X).to_csv(\"../../result/emb/hdbscan_dagma.txt\", sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6a7947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = pd.read_csv(\"../../result/input_perturb_phyloP/%d/genes_train_valid_test_stratified\" % rs, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "278258b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes[1] = cluster_label_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "657b80b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes[1].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1764884e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\n",
       "-1     550\n",
       " 41     56\n",
       " 61     48\n",
       " 10     48\n",
       " 31     39\n",
       "      ... \n",
       " 60     11\n",
       " 23     11\n",
       " 45     11\n",
       " 81     10\n",
       " 80     10\n",
       "Name: count, Length: 83, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "248876a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes.to_csv(\"../../result/emb/hdbscan_dagma.txt\", sep=\"\\t\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
