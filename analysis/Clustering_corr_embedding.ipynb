{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e17e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from scipy.stats import pearsonr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import pymde\n",
    "import hdbscan\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34b80228",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/slayman/pi/gerstein/jg2447/conda_envs/DAG/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/gpfs/slayman/pi/gerstein/jg2447/conda_envs/DAG/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/gpfs/slayman/pi/gerstein/jg2447/conda_envs/DAG/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/gpfs/slayman/pi/gerstein/jg2447/conda_envs/DAG/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/gpfs/slayman/pi/gerstein/jg2447/conda_envs/DAG/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/gpfs/slayman/pi/gerstein/jg2447/conda_envs/DAG/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4424: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n"
     ]
    }
   ],
   "source": [
    "p_nw = []\n",
    "p_net_nw = []\n",
    "loss_nw = []\n",
    "loss_net_nw = []\n",
    "bool_nw = []\n",
    "\n",
    "for network_name in [\"CoExpr_perturb_0.5\"]:\n",
    "    \n",
    "    # measurements across 10 random sample split\n",
    "    p_rs = []\n",
    "    p_net_rs = []\n",
    "    loss_rs = []\n",
    "    loss_net_rs = []\n",
    "    bool_rs = []\n",
    "    \n",
    "    for rs in range(10):\n",
    "        # read data\n",
    "        X_train = pd.read_csv(\"../../result/input_perturb_phyloP/%d/X_train_stratified\" % rs, sep=\"\\t\", index_col=0).values\n",
    "        X_valid = pd.read_csv(\"../../result/input_perturb_phyloP/%d/X_valid_stratified\" % rs, sep=\"\\t\", index_col=0).values\n",
    "        X_test = pd.read_csv(\"../../result/input_perturb_phyloP/%d/X_test_stratified\" % rs, sep=\"\\t\", index_col=0).values\n",
    "        Y_test = pd.read_csv(\"../../result/input_perturb_phyloP/%d/Y_test_stratified\" % rs, sep=\"\\t\", index_col=0).values.reshape(-1)\n",
    "        Y_test_gene = pd.read_csv(\"../../result/input_perturb_phyloP/%d/Y_test_stratified\" % rs, sep=\"\\t\", index_col=0).index\n",
    "\n",
    "        test_mask = np.concatenate([[False] * len(X_train), [False] * len(X_valid), [True] * len(X_test)])\n",
    "\n",
    "        # mask of whether a test node is in the DAGMA graph\n",
    "        dag = pd.read_csv(\"../../result/network_perturb_phyloP/DAGMA_thresholdAdaptive.tsv\", sep=\"\\t\", header=None)\n",
    "        id2genes = pd.read_csv(\"../../result/network_perturb_phyloP/valid_genes\", sep=\"\\t\").set_index(\"ID\")['genes'].to_dict()\n",
    "        dag[0] = dag[0].map(id2genes)\n",
    "        dag[1] = dag[1].map(id2genes)\n",
    "        dag_genes = list(set.union(set(dag[0]), set(dag[1])))\n",
    "        test_inDAG = Y_test_gene.isin(dag_genes)\n",
    "\n",
    "        # measurements across 10 random init repeats\n",
    "        p_rep = []\n",
    "        p_net_rep = []\n",
    "        loss_rep = []\n",
    "        loss_net_rep = []\n",
    "\n",
    "        for rep in range(10):\n",
    "            prefix = \"../../result/model_perturb_phyloP/%s/%d/model%d\" % (network_name, rs, rep)\n",
    "            with open(prefix+\".para\", \"rb\") as f:\n",
    "                best_params, X1, out, loss1, loss2 = pickle.load(f)\n",
    "            Y_pred = out[test_mask].reshape(-1)\n",
    "\n",
    "            loss_rep.append(F.mse_loss(torch.tensor(Y_test), torch.tensor(Y_pred)).item())\n",
    "            loss_net_rep.append(F.mse_loss(torch.tensor(Y_test[test_inDAG]), torch.tensor(Y_pred[test_inDAG])).item())\n",
    "            p_rep.append(pearsonr(Y_test, Y_pred)[0])\n",
    "            p_net_rep.append(pearsonr(Y_test[test_inDAG], Y_pred[test_inDAG])[0])\n",
    "        bool_rep = ~np.isnan(np.array(p_net_rep))\n",
    "\n",
    "        p_rs.append(p_rep)\n",
    "        p_net_rs.append(p_net_rep)\n",
    "        loss_rs.append(loss_rep)\n",
    "        loss_net_rs.append(loss_net_rep)\n",
    "        bool_rs.append(bool_rep)\n",
    "        \n",
    "    p_nw.append(p_rs)\n",
    "    p_net_nw.append(p_net_rs)\n",
    "    loss_nw.append(loss_rs)\n",
    "    loss_net_nw.append(loss_net_rs)\n",
    "    bool_nw.append(bool_rs)\n",
    "\n",
    "p_nw = np.array(p_nw)\n",
    "p_net_nw = np.array(p_net_nw)\n",
    "loss_nw = np.array(loss_nw)\n",
    "loss_net_nw = np.array(loss_net_nw)\n",
    "bool_nw = np.array(bool_nw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7174dd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanargmin(loss_nw[0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40726ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_name = \"CoExpr_perturb_0.5\"\n",
    "rs = 4\n",
    "rep = 8\n",
    "\n",
    "# read data\n",
    "X_train = pd.read_csv(\"../../result/input_perturb_phyloP/%d/X_train_stratified\" % rs, sep=\"\\t\", index_col=0).values\n",
    "X_valid = pd.read_csv(\"../../result/input_perturb_phyloP/%d/X_valid_stratified\" % rs, sep=\"\\t\", index_col=0).values\n",
    "X_test = pd.read_csv(\"../../result/input_perturb_phyloP/%d/X_test_stratified\" % rs, sep=\"\\t\", index_col=0).values\n",
    "Y_test = pd.read_csv(\"../../result/input_perturb_phyloP/%d/Y_test_stratified\" % rs, sep=\"\\t\", index_col=0).values.reshape(-1)\n",
    "Y_test_gene = pd.read_csv(\"../../result/input_perturb_phyloP/%d/Y_test_stratified\" % rs, sep=\"\\t\", index_col=0).index\n",
    "\n",
    "test_mask = np.concatenate([[False] * len(X_train), [False] * len(X_valid), [True] * len(X_test)])\n",
    "\n",
    "# mask of whether a test node is in the DAGMA graph\n",
    "dag = pd.read_csv(\"../../result/network_perturb_phyloP/DAGMA_thresholdAdaptive.tsv\", sep=\"\\t\", header=None)\n",
    "id2genes = pd.read_csv(\"../../result/network_perturb_phyloP/valid_genes\", sep=\"\\t\").set_index(\"ID\")['genes'].to_dict()\n",
    "dag[0] = dag[0].map(id2genes)\n",
    "dag[1] = dag[1].map(id2genes)\n",
    "dag_genes = list(set.union(set(dag[0]), set(dag[1])))\n",
    "test_inDAG = Y_test_gene.isin(dag_genes)\n",
    "\n",
    "prefix = \"../../result/model_perturb_phyloP/%s/%d/model%d\" % (network_name, rs, rep)\n",
    "with open(prefix+\".para\", \"rb\") as f:\n",
    "    best_params, X1, out, loss1, loss2 = pickle.load(f)\n",
    "Y_pred = out[test_mask].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53c32c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dec 14 05:21:15 PM: Your dataset appears to contain duplicated items (rows); when embedding, you should typically have unique items.\n",
      "Dec 14 05:21:15 PM: The following items have duplicates [   4   28   47   52   71   96  103  106  193  681  831  833  841 1046\n",
      " 1173 1388 1390 2141]\n"
     ]
    }
   ],
   "source": [
    "# z-norm expression profile from given data\n",
    "X = X1\n",
    "X_norm = StandardScaler().fit_transform(X)\n",
    "\n",
    "# # init with spectral embed\n",
    "# se = SpectralEmbedding(n_components=20, affinity='nearest_neighbors', n_neighbors=7, eigen_solver='arpack')\n",
    "# X_norm_se = se.fit_transform(X_norm)\n",
    "\n",
    "# mde embed\n",
    "mde = pymde.preserve_neighbors(X_norm, embedding_dim=20, n_neighbors=7, repulsive_fraction=5)\n",
    "X_norm_se_mde = mde.embed()\n",
    "pd.DataFrame(X_norm_se_mde).to_csv(\"../../result/emb/mde_corr.txt\", sep=\"\\t\", header=False, index=False)\n",
    "\n",
    "# clustering\n",
    "clusterer = hdbscan.HDBSCAN(metric='euclidean', min_cluster_size=10, min_samples=10, cluster_selection_method='leaf')\n",
    "cluster_label_X = clusterer.fit_predict(X_norm_se_mde)\n",
    "pd.DataFrame(cluster_label_X).to_csv(\"../../result/emb/hdbscan_corr.txt\", sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6a7947a",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = pd.read_csv(\"../../result/input_perturb_phyloP/%d/genes_train_valid_test_stratified\" % rs, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "278258b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes[1] = cluster_label_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "657b80b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes[1].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1764884e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\n",
       "-1      324\n",
       " 50     112\n",
       " 6       33\n",
       " 98      33\n",
       " 92      32\n",
       "       ... \n",
       " 4       11\n",
       " 88      11\n",
       " 105     10\n",
       " 16      10\n",
       " 76      10\n",
       "Name: count, Length: 110, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "248876a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes.to_csv(\"../../result/emb/hdbscan_corr.txt\", sep=\"\\t\", index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
